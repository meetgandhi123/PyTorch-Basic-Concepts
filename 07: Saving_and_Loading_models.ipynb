{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saving and Loading models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lrs1v42rop18",
        "8ckySMLHpof5",
        "8IgXAJ_osRqT"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtjuA9guPg85YBjNFCvOJ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meetgandhi123/PyTorch-Basic-Concepts/blob/main/Saving_and_Loading_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrs1v42rop18"
      },
      "source": [
        "### Method 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjLtlfWVpevc"
      },
      "source": [
        "Save Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFo7azxynrs5",
        "outputId": "485d49d9-a3c5-4ad5-9a9f-39fc13a83ac6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "\n",
        "model = Model(n_input_features=10)\n",
        "# training of your model...\n",
        "\n",
        "FILE = \"model_method1.pth\"\n",
        "torch.save(model,FILE)\n",
        "\n",
        "for params in model.parameters():\n",
        "    print(params)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0503, -0.0934, -0.1071,  0.2120,  0.1271,  0.1475,  0.0065, -0.0234,\n",
            "         -0.3010, -0.0805]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2222], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iHJA3DjphzC"
      },
      "source": [
        "Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BJTRiAzpurA",
        "outputId": "66a65434-26e5-4a50-b76a-44743a504e28"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "FILE = \"/content/model_method1.pth\"\n",
        "\n",
        "loaded_model = torch.load(FILE)\n",
        "loaded_model.eval()\n",
        "\n",
        "for params in loaded_model.parameters():\n",
        "    print(params)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0503, -0.0934, -0.1071,  0.2120,  0.1271,  0.1475,  0.0065, -0.0234,\n",
            "         -0.3010, -0.0805]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2222], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ckySMLHpof5"
      },
      "source": [
        "## Method 2 (Recommended) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OvkKyqZqp-j"
      },
      "source": [
        "Save Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtNdMTiDot_6",
        "outputId": "94fadc5d-2605-4e9e-9cd5-f2abeaf64ba0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "\n",
        "model = Model(n_input_features=10)\n",
        "# training of your model...\n",
        "\n",
        "FILE = \"model_method2.pth\"\n",
        "torch.save(model.state_dict(),FILE)\n",
        "\n",
        "#print(model.state_dict())\n",
        "#OrderedDict([('linear.weight', tensor([[ 0.2519,  0.2721, -0.0873, -0.0048,  0.1739, -0.1456,  0.2998, -0.1276,\n",
        "#          0.0670,  0.2060]])), ('linear.bias', tensor([-0.1913]))])\n",
        "\n",
        "for params in model.parameters():\n",
        "    print(params)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2519,  0.2721, -0.0873, -0.0048,  0.1739, -0.1456,  0.2998, -0.1276,\n",
            "          0.0670,  0.2060]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1913], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rF0PCQ-qraq"
      },
      "source": [
        "Load Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSRfe0T-qmgP",
        "outputId": "ce184926-9b8f-4901-881c-fc9ada25c43f"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "\n",
        "FILE = \"/content/model_method2.pth\"\n",
        "\n",
        "loaded_model = Model(n_input_features=10)\n",
        "loaded_model.load_state_dict(torch.load(FILE))\n",
        "\n",
        "loaded_model.eval()\n",
        "\n",
        "for params in loaded_model.parameters():\n",
        "    print(params)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.2519,  0.2721, -0.0873, -0.0048,  0.1739, -0.1456,  0.2998, -0.1276,\n",
            "          0.0670,  0.2060]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.1913], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IgXAJ_osRqT"
      },
      "source": [
        "## Saving optimizers along with model in checkpoint file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HL_jrwEuTFz"
      },
      "source": [
        "Save checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9tdO2ZxrLEw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,n_input_features):\n",
        "        super(Model,self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "    \n",
        "model = Model(n_input_features=10)\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#print(optimizer.state_dict())\n",
        "#{'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]}\n",
        "\n",
        "checkpoint = {\n",
        "    \"epoch\" : 5,\n",
        "    \"model_state\" : model.state_dict(),\n",
        "    \"optimizer_state\" : optimizer.state_dict() \n",
        "}\n",
        "\n",
        "torch.save(checkpoint,\"checkpoint.pth\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHg9ZY0xuWNj"
      },
      "source": [
        "Load Checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsMK25Kpt6sB",
        "outputId": "bd33d679-788a-4e83-fbe0-03395d2a24fe"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,n_input_features):\n",
        "        super(Model,self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "    \n",
        "loaded_checkpoint = torch.load(\"/content/checkpoint.pth\")\n",
        "\n",
        "epoch = loaded_checkpoint[\"epoch\"]\n",
        "loaded_model = Model(n_input_features=10)\n",
        "loaded_optimizer = torch.optim.SGD(loaded_model.parameters(), lr=0)\n",
        "\n",
        "loaded_model.load_state_dict(checkpoint[\"model_state\"])\n",
        "loaded_optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
        "\n",
        "#print(optimizer.state_dict())\n",
        "#{'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdQ4vJb6vhOq"
      },
      "source": [
        "## Save model on GPU and Load it on CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLO90T2tvj0T"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Save model on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.save_dict(), PATH)\n",
        "\n",
        "# Load model on CPU\n",
        "device = torch.device(\"cpu\")\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifnPp2UHwJSd"
      },
      "source": [
        "## Save model on GPU and Load it on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950KFeVgwLnq"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Save model on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.save_dict(), PATH)\n",
        "\n",
        "# Load model on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqwhT8AhwabD"
      },
      "source": [
        "## Save model on CPU and Load it on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v53zSsQywdVr"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Save model on CPU\n",
        "torch.save(model.save_dict(), PATH)\n",
        "\n",
        "# Load model on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\")) # GPU device number.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
